{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"k_WTA_keras3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IpYgko9QarAK"},"source":["# 準備"]},{"cell_type":"markdown","metadata":{"id":"pCaVa2R5bq_4"},"source":["## artのインストール"]},{"cell_type":"code","metadata":{"id":"QoNsAnXUmgST"},"source":["!pip3 install adversarial-robustness-toolbox"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Us1-UrOXaw87"},"source":["## ライブラリのインポート"]},{"cell_type":"code","metadata":{"id":"wF3Foi62mnPi"},"source":["import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow with Keras.\n","import tensorflow as tf\n","import keras\n","from keras.models import Model\n","from keras.layers import Input, Dense, Flatten, Conv2D, Lambda\n","from keras.layers import MaxPooling2D, GlobalAveragePooling2D, Dropout\n","tf.compat.v1.disable_eager_execution()\n","from keras import backend as K\n","\n","# ART\n","import art\n","from art.attacks.evasion import FastGradientMethod\n","from art.estimators.classification import KerasClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qsjVGzIwaz1c"},"source":["## CIFAR10のロード・前処理"]},{"cell_type":"code","metadata":{"id":"NJn7yF4_mwM_"},"source":["# CIFAR10のロード。\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","# CIFAR10のラベル。\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","num_classes = len(classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zOnIFWanCRE"},"source":["# 正規化。\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.astype('float32') / 255\n","\n","# ラベルをOne-hot-vector化。\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BIh32W6raz6l"},"source":["# Classifier(k-WTAなし)の作成\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VYm8pYF6btOr"},"source":["## モデル定義"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkhVRmdcnG4G","outputId":"fbe6bd83-74b9-47db-a2df-c18e4789d7ee"},"source":["# モデルの定義。\n","inputs = Input(shape=(32, 32, 3))\n","x = Conv2D(64, (3, 3), padding='SAME', activation='relu')(inputs)\n","x = Conv2D(64, (3, 3), padding='SAME', activation='relu')(x)\n","x = Dropout(0.25)(x)\n","x = MaxPooling2D()(x)\n","\n","x = Conv2D(128, (3,3), padding='SAME', activation='relu')(x)\n","x = Conv2D(128, (3,3), padding='SAME', activation='relu')(x)\n","x = Dropout(0.25)(x)\n","x = MaxPooling2D()(x)\n","\n","x = Conv2D(256, (3,3), padding='SAME', activation='relu')(x)\n","x = Conv2D(256, (3,3), padding='SAME', activation='relu')(x)\n","x = GlobalAveragePooling2D()(x)\n","\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.25)(x)\n","y = Dense(10, activation='softmax')(x)\n","\n","model = Model(inputs, y)\n","\n","# モデルのコンパイル。\n","model.compile(optimizer=tf.keras.optimizers.Adam(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_17\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_31 (InputLayer)        [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv2d_116 (Conv2D)          (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","conv2d_117 (Conv2D)          (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","dropout_81 (Dropout)         (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_34 (MaxPooling (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_118 (Conv2D)          (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","conv2d_119 (Conv2D)          (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","dropout_82 (Dropout)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_35 (MaxPooling (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_120 (Conv2D)          (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","conv2d_121 (Conv2D)          (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","global_average_pooling2d_17  (None, 256)               0         \n","_________________________________________________________________\n","dense_64 (Dense)             (None, 1024)              263168    \n","_________________________________________________________________\n","dropout_83 (Dropout)         (None, 1024)              0         \n","_________________________________________________________________\n","dense_65 (Dense)             (None, 10)                10250     \n","=================================================================\n","Total params: 1,418,826\n","Trainable params: 1,418,826\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"gwFlvnrDbH7N"},"source":["## 学習の実行"]},{"cell_type":"markdown","metadata":{"id":"l9TbV14fbSGI"},"source":["## モデルの精度評価"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"iRnFClSCnKP-","outputId":"6cb47b9b-56fd-4527-f5cd-287a8ab777e6"},"source":["# 学習の実行。\n","model.fit(X_train, y_train,\n","          batch_size=512,\n","          epochs=30,\n","          validation_data=(X_test, y_test),\n","          shuffle=True)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/30\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/dv/_837vmqs5yl0tklsbq8k7mdm0000gn/T/ipykernel_94883/545656769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           shuffle=True)\n\u001b[0m","\u001b[0;32m~/opt/anaconda3/envs/k-wta/lib/python3.7/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n","\u001b[0;32m~/opt/anaconda3/envs/k-wta/lib/python3.7/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   def evaluate(self,\n","\u001b[0;32m~/opt/anaconda3/envs/k-wta/lib/python3.7/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/k-wta/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4031\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4032\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4033\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4034\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n","\u001b[0;32m~/opt/anaconda3/envs/k-wta/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1479\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"S656RWtknM8r"},"source":["model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1P3oVot2qMdb"},"source":["# Classifier(k-WTAあり)の作成"]},{"cell_type":"markdown","metadata":{"id":"jLjl3-B6qmH9"},"source":["## k-WTAの作成"]},{"cell_type":"code","metadata":{"id":"q4fSArArqorP"},"source":["class KWTA(tf.keras.layers.Layer):\n","  def __init__(self, k=None, **kwargs) :\n","    super().__init__(**kwargs)\n","    self.k = k\n","\n","  def call(self, x):\n","    n = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n","    if self.k == None:\n","            k = n * 7 // 10\n","        else:\n","            k = self.k\n","    topk = tf.math.top_k(x[0], k=k)   # 上位k個の値を抽出\n","    topk_min = K.min(topk.values)         # topkの最小値を抽出\n","    comp = tf.dtypes.cast(x >= topk_min, tf.float32)   # topkの最小値以上の値の部分を1, より小さい値の部分を0にしたTensorを生成\n","    return tf.math.multiply(x,comp)        # x * compより、topkの最小値以上の値のみそのまま、他は0になるようにする\n","\n","class KWTA2D(tf.keras.layers.Layer):\n","    def __init__(self, k=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.k = k\n","        \n","    def call(self, x):\n","        n = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n","        if self.k == None:\n","            k = n * 7 // 10\n","        else:\n","            k = self.k\n","        x_flatten = tf.reshape(x[0],  [n])\n","        topk = tf.math.top_k(x_flatten, k=k)\n","        topk_min = K.min(topk.values) \n","        comp = tf.dtypes.cast(x >= topk_min, tf.float32)\n","        return tf.math.multiply(x,comp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PekcoaIBqQtm"},"source":["## モデル定義"]},{"cell_type":"code","metadata":{"id":"aXYxX_ckqXho","outputId":"adbc6fee-6d00-490d-cd88-1afece50e28c"},"source":["# モデルの定義。\n","inputs = Input(shape=(32, 32, 3))\n","x = Conv2D(64, (3, 3), padding='SAME')(inputs)\n","x = KWTA2D()(x)\n","x = Conv2D(64, (3, 3), padding='SAME')(x)\n","x = KWTA2D()(x)\n","x = Dropout(0.25)(x)\n","x = MaxPooling2D()(x)\n","\n","x = Conv2D(128, (3,3), padding='SAME')(x)\n","x = KWTA2D()(x)\n","x = Conv2D(128, (3,3), padding='SAME')(x)\n","x = KWTA2D()(x)\n","x = Dropout(0.25)(x)\n","x = MaxPooling2D()(x)\n","\n","x = Conv2D(256, (3,3), padding='SAME')(x)\n","x = KWTA2D()(x)\n","x = Conv2D(256, (3,3), padding='SAME')(x)\n","x = KWTA2D()(x)\n","x = GlobalAveragePooling2D()(x)\n","\n","x = Dense(1024)(x)\n","x = KWTA(512)(x)\n","x = Dropout(0.25)(x)\n","y = Dense(10, activation='softmax')(x)\n","\n","model_kwta = Model(inputs, y)\n","\n","# モデルのコンパイル。\n","model_kwta.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model_kwta.summary()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_21\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_35 (InputLayer)        [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv2d_140 (Conv2D)          (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","kwt_a2d_56 (KWTA2D)          (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_141 (Conv2D)          (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","kwt_a2d_57 (KWTA2D)          (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","dropout_93 (Dropout)         (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_42 (MaxPooling (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_142 (Conv2D)          (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","kwt_a2d_58 (KWTA2D)          (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_143 (Conv2D)          (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","kwt_a2d_59 (KWTA2D)          (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","dropout_94 (Dropout)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_43 (MaxPooling (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_144 (Conv2D)          (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","kwt_a2d_60 (KWTA2D)          (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_145 (Conv2D)          (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","kwt_a2d_61 (KWTA2D)          (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","global_average_pooling2d_21  (None, 256)               0         \n","_________________________________________________________________\n","dense_72 (Dense)             (None, 1024)              263168    \n","_________________________________________________________________\n","kwta_46 (KWTA)               (None, 1024)              0         \n","_________________________________________________________________\n","dropout_95 (Dropout)         (None, 1024)              0         \n","_________________________________________________________________\n","dense_73 (Dense)             (None, 10)                10250     \n","=================================================================\n","Total params: 1,418,826\n","Trainable params: 1,418,826\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"9NuJ90N8AsQZ"},"source":["## 学習の実行"]},{"cell_type":"code","metadata":{"id":"hYkVnIT9Ak0g","outputId":"59841065-5e6b-42f3-d6e9-107e57fb8034"},"source":["# 学習の実行。\n","model_kwta.fit(X_train, y_train,\n","          batch_size=512,\n","          epochs=30,\n","          validation_data=(X_test, y_test),\n","          shuffle=True)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/30\n","50000/50000 [==============================] - 250s 5ms/sample - loss: 2.0748 - accuracy: 0.2090 - val_loss: 2.6120 - val_accuracy: 0.1786\n","Epoch 2/30\n","50000/50000 [==============================] - 246s 5ms/sample - loss: 1.7651 - accuracy: 0.3173 - val_loss: 1.9447 - val_accuracy: 0.3140\n","Epoch 3/30\n","50000/50000 [==============================] - 245s 5ms/sample - loss: 1.6901 - accuracy: 0.3650 - val_loss: 1.6827 - val_accuracy: 0.3882\n","Epoch 4/30\n","50000/50000 [==============================] - 230s 5ms/sample - loss: 1.4517 - accuracy: 0.4656 - val_loss: 1.4615 - val_accuracy: 0.4695\n","Epoch 5/30\n","50000/50000 [==============================] - 228s 5ms/sample - loss: 1.3163 - accuracy: 0.5188 - val_loss: 1.3549 - val_accuracy: 0.5228\n","Epoch 6/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 1.2658 - accuracy: 0.5407 - val_loss: 1.3671 - val_accuracy: 0.5537\n","Epoch 7/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 1.1157 - accuracy: 0.6014 - val_loss: 1.2221 - val_accuracy: 0.5782\n","Epoch 8/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 1.0346 - accuracy: 0.6319 - val_loss: 1.7009 - val_accuracy: 0.5065\n","Epoch 9/30\n","50000/50000 [==============================] - 228s 5ms/sample - loss: 1.0284 - accuracy: 0.6338 - val_loss: 1.3362 - val_accuracy: 0.5642\n","Epoch 10/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.9687 - accuracy: 0.6567 - val_loss: 1.0087 - val_accuracy: 0.6558\n","Epoch 11/30\n","50000/50000 [==============================] - 226s 5ms/sample - loss: 0.8389 - accuracy: 0.7013 - val_loss: 0.9497 - val_accuracy: 0.6692\n","Epoch 12/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.8446 - accuracy: 0.7036 - val_loss: 1.1326 - val_accuracy: 0.6224\n","Epoch 13/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.9431 - accuracy: 0.6711 - val_loss: 0.9771 - val_accuracy: 0.6844\n","Epoch 14/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.7475 - accuracy: 0.7367 - val_loss: 0.9150 - val_accuracy: 0.6832\n","Epoch 15/30\n","50000/50000 [==============================] - 228s 5ms/sample - loss: 0.7743 - accuracy: 0.7298 - val_loss: 0.8568 - val_accuracy: 0.7043\n","Epoch 16/30\n","50000/50000 [==============================] - 228s 5ms/sample - loss: 0.7383 - accuracy: 0.7428 - val_loss: 0.8302 - val_accuracy: 0.7163\n","Epoch 17/30\n","50000/50000 [==============================] - 229s 5ms/sample - loss: 0.6662 - accuracy: 0.7655 - val_loss: 0.9098 - val_accuracy: 0.6931\n","Epoch 18/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.6161 - accuracy: 0.7841 - val_loss: 0.7436 - val_accuracy: 0.7466\n","Epoch 19/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.5924 - accuracy: 0.7932 - val_loss: 0.7076 - val_accuracy: 0.7590\n","Epoch 20/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.5975 - accuracy: 0.7894 - val_loss: 0.9375 - val_accuracy: 0.6952\n","Epoch 21/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.5959 - accuracy: 0.7919 - val_loss: 0.7501 - val_accuracy: 0.7465\n","Epoch 22/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.5367 - accuracy: 0.8129 - val_loss: 0.6746 - val_accuracy: 0.7695\n","Epoch 23/30\n","50000/50000 [==============================] - 229s 5ms/sample - loss: 0.5197 - accuracy: 0.8172 - val_loss: 0.6616 - val_accuracy: 0.7803\n","Epoch 24/30\n","50000/50000 [==============================] - 227s 5ms/sample - loss: 0.5102 - accuracy: 0.8206 - val_loss: 0.6729 - val_accuracy: 0.7788\n","Epoch 25/30\n","50000/50000 [==============================] - 229s 5ms/sample - loss: 0.5056 - accuracy: 0.8224 - val_loss: 0.7167 - val_accuracy: 0.7593\n","Epoch 26/30\n","50000/50000 [==============================] - 228s 5ms/sample - loss: 0.4774 - accuracy: 0.8335 - val_loss: 0.9415 - val_accuracy: 0.6993\n","Epoch 27/30\n","50000/50000 [==============================] - 228s 5ms/sample - loss: 0.4639 - accuracy: 0.8353 - val_loss: 0.6522 - val_accuracy: 0.7938\n","Epoch 28/30\n","50000/50000 [==============================] - 232s 5ms/sample - loss: 0.4191 - accuracy: 0.8528 - val_loss: 0.7690 - val_accuracy: 0.7694\n","Epoch 29/30\n","50000/50000 [==============================] - 234s 5ms/sample - loss: 0.4316 - accuracy: 0.8509 - val_loss: 0.6883 - val_accuracy: 0.7816\n","Epoch 30/30\n","50000/50000 [==============================] - 229s 5ms/sample - loss: 0.3861 - accuracy: 0.8648 - val_loss: 0.6443 - val_accuracy: 0.7884\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fbe9037bbd0>"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"MRrec6CqAlhT"},"source":["## モデルの精度評価"]},{"cell_type":"code","metadata":{"id":"ING1BhjUAvTH","outputId":"5865366f-d5ee-4982-9b87-720cb9ad4eac"},"source":["model_kwta.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[{"data":{"text/plain":["[0.6477729416370391, 0.7924]"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"cyHAo6D4CL8s"},"source":["# 敵対的攻撃"]},{"cell_type":"markdown","metadata":{"id":"iyFSzXUCb--B"},"source":["## 非標的型攻撃としてのFGSMによる摂動を作成\n","以下、この摂動を上乗せした画像のことを「敵対的画像」と呼ぶ。"]},{"cell_type":"code","metadata":{"id":"K12B6fnsn1GV"},"source":["# 入力データの特徴量の最小値・最大値を指定。\n","# 特徴量は0.0～1.0の範囲に収まるように正規化しているため、最小値は0.0、最大値は1.0とする。\n","min_pixel_value = 0.0\n","max_pixel_value = 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1gGVkHO1oOKz"},"source":["### k-WTAなし"]},{"cell_type":"code","metadata":{"id":"Z-1z-Rban7-c"},"source":["# モデルをART Keras Classifierでラップ。\n","classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)\n","# FGSMインスタンスの作成。\n","attack = FastGradientMethod(estimator=classifier, eps=0.10, targeted=False)\n","# 敵対的サンプルの生成（ベース画像はテストデータとする）。\n","X_adv = attack.generate(x=X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GNa-IoVCoOKz"},"source":["### k-WTAあり"]},{"cell_type":"code","metadata":{"id":"kDNDkKvacPJM"},"source":["classifier_kwta = KerasClassifier(model=model_kwta, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)\n","attack_kwta = FastGradientMethod(estimator=classifier_kwta, eps=0.10, targeted=False)\n","X_adv_kwta = attack_kwta.generate(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wqsgeVgpcwoJ"},"source":["## 敵対的画像に対するモデルの精度評価"]},{"cell_type":"markdown","metadata":{"id":"zF8ZudkKoOKz"},"source":["### k-WTAなし"]},{"cell_type":"code","metadata":{"id":"VgplWIjECQud"},"source":["model.evaluate(X_adv, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMYgKirzoOK0"},"source":["### k-WTAあり"]},{"cell_type":"code","metadata":{"id":"2O14VsPkCVxY","outputId":"eabd81af-7678-4328-b89b-566c954080c8"},"source":["model_kwta.evaluate(X_adv_kwta, y_test)"],"execution_count":null,"outputs":[{"data":{"text/plain":["[6.555474308013916, 0.1146]"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"ns__xrtYoOK0"},"source":[""],"execution_count":null,"outputs":[]}]}